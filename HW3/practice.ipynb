{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stem(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Stem, self).__init__()\n",
    "\n",
    "        # Initial Convolution\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Mixed 4x4 Convolution\n",
    "        self.mixed_conv1 = nn.Conv2d(64, 96, kernel_size=3, stride=2, padding=0)\n",
    "\n",
    "        # Mixed 7x7 Convolution\n",
    "        self.mixed_conv2 = nn.Conv2d(64, 64, kernel_size=1, padding=0)\n",
    "        self.mixed_conv3 = nn.Conv2d(64, 96, kernel_size=3, padding=0)\n",
    "\n",
    "        # Pooling\n",
    "        self.max_pool1 = nn.MaxPool2d(3, stride=2, padding=0)\n",
    "\n",
    "        # Reduction\n",
    "        self.conv4 = nn.Conv2d(160, 64, kernel_size=1, padding=0)\n",
    "        self.conv5 = nn.Conv2d(64, 96, kernel_size=3, padding=0)\n",
    "        self.conv6 = nn.Conv2d(160, 64, kernel_size=1, padding=0)\n",
    "        self.conv7 = nn.Conv2d(64, 64, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.conv8 = nn.Conv2d(64, 64, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.conv9 = nn.Conv2d(64, 96, kernel_size=3, padding=0)\n",
    "\n",
    "        # Final Max Pooling\n",
    "        self.max_pool2 = nn.MaxPool2d(3, stride=2, padding=0)\n",
    "        self.mixed_conv2 = nn.Conv2d(192, 192, kernel_size=3, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial Conv Layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        # Two parallel strided operations\n",
    "        x0 = self.mixed_conv1(x)\n",
    "        x1 = self.max_pool1(x)\n",
    "\n",
    "        # Concatenation\n",
    "        x = torch.cat((x0, x1), dim=1)\n",
    "\n",
    "        # First 7x7 Mixed Conv\n",
    "        x0 = F.relu(self.conv4(x))\n",
    "        x0 = F.relu(self.conv5(x0))\n",
    "\n",
    "        # Second 7x7 Mixed Conv\n",
    "        x1 = F.relu(self.conv6(x))\n",
    "        x1 = F.relu(self.conv7(x1))\n",
    "        x1 = F.relu(self.conv8(x1))\n",
    "        x1 = F.relu(self.conv9(x1))\n",
    "\n",
    "        # Concatenation\n",
    "        x = torch.cat((x0, x1), dim=1)\n",
    "\n",
    "        # Final Max Pooling\n",
    "        x0 = self.max_pool2(x)\n",
    "        x1 = self.mixed_conv2(x)\n",
    "\n",
    "        # Final Concatenation\n",
    "        x = torch.cat((x0, x1), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "class InceptionResNetA(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionResNetA, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 48, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(48, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.reduction1x1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 384, kernel_size=1),  ### original 384\\\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch0 = self.branch0(x)\n",
    "\n",
    "        branch1 = self.branch1(x)\n",
    "\n",
    "        branch2 = self.branch2(x)\n",
    "\n",
    "        branches = [branch0, branch1, branch2]\n",
    "        mixed = torch.cat(branches, dim=1)\n",
    "\n",
    "        up = self.reduction1x1(mixed)\n",
    "\n",
    "        out = up * 0.1 + x\n",
    "        ####relu\n",
    "        return out\n",
    "\n",
    "class ReductionA(nn.Module):\n",
    "    def __init__(self, in_channels, k, l, m, n):\n",
    "        super(ReductionA, self).__init__()\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, n, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(n),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, k, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(k),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(k, l, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(l),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(l, m, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(m),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.MaxPool2d(3, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "\n",
    "        return torch.cat((x1, x2, x3), 1)\n",
    "\n",
    "class InceptionResNetB(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionResNetB, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 192, kernel_size=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 128, kernel_size=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 160, kernel_size=(1, 7), padding=(0, 3)),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(160, 192, kernel_size=(7, 1), padding=(3, 0)),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.reduction1x1 = nn.Sequential(\n",
    "            nn.Conv2d(384, in_channels, kernel_size=1),    #### change channel\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU()\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch0 = self.branch0(x)\n",
    "        branch1 = self.branch1(x)\n",
    "\n",
    "        branches = [branch0, branch1]\n",
    "        mixed = torch.cat(branches, dim=1)\n",
    "\n",
    "        up = self.reduction1x1(mixed)\n",
    "\n",
    "        out = up * 0.1 + x\n",
    "        return out\n",
    "\n",
    "class ReductionB(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ReductionB, self).__init__()\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 256, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 256, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 288, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(288),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 256, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 288, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(288),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(288, 320, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.MaxPool2d(3, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        x4 = self.branch4(x)\n",
    "\n",
    "        return torch.cat((x1, x2, x3, x4), 1)\n",
    "\n",
    "class InceptionResNetC(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionResNetC, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Conv2d(in_channels, 192, kernel_size=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 192, kernel_size=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 224, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(224),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(224, 256, kernel_size=(3, 1), padding=(1, 0)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.reduction1x1 = nn.Sequential(\n",
    "            nn.Conv2d(448, in_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch0 = self.branch0(x)\n",
    "        branch1 = self.branch1(x)\n",
    "\n",
    "        branches = [branch0, branch1]\n",
    "        mixed = torch.cat(branches, dim=1)\n",
    "\n",
    "        up = self.reduction1x1(mixed)\n",
    "\n",
    "        out = up * 0.1 + x\n",
    "\n",
    "        return out\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = nn.ReLU()(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = nn.ReLU()(out)\n",
    "\n",
    "        return out\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
